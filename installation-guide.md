# üì¶ Guide d'Installation - SmolLM3 & SmolVLM2

Guide complet pour installer et ex√©cuter l'interface Gradio sur **macOS** et **Windows 11**.

---

## üçé Installation sur macOS

### Pr√©requis
- macOS 11.0 (Big Sur) ou sup√©rieur
- Pour Apple Silicon (M1/M2/M3): utilisation automatique de MPS
- Pour Intel Mac: utilisation CPU ou GPU externe

### √âtape 1: Installer Homebrew (si pas d√©j√† install√©)

```bash
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

### √âtape 2: Installer Python 3.10+

```bash
# Installer Python via Homebrew
brew install python@3.11

# V√©rifier l'installation
python3 --version
```

### √âtape 3: Cr√©er un environnement virtuel

```bash
# Cr√©er un dossier pour le projet
mkdir ~/smollm-app
cd ~/smollm-app

# Cr√©er un environnement virtuel
python3 -m venv venv

# Activer l'environnement
source venv/bin/activate
```

### √âtape 4: Installer les d√©pendances

```bash
# Mettre √† jour pip
pip install --upgrade pip

# Installer PyTorch pour Mac (avec support MPS pour Apple Silicon)
pip install torch torchvision torchaudio

# Installer les autres d√©pendances
pip install transformers>=4.53.0 gradio>=4.0.0 accelerate pillow sentencepiece protobuf

# Pour optimiser les performances sur Apple Silicon
pip install accelerate bitsandbytes
```

### √âtape 5: T√©l√©charger et lancer l'application

```bash
# Cr√©er le fichier Python (copier le code de l'artefact)
nano app.py
# Coller le code, puis Ctrl+O pour sauvegarder, Ctrl+X pour quitter

# Ou t√©l√©charger directement si vous avez le fichier
# curl -O https://votre-url/app.py

# Lancer l'application
python app.py
```

### √âtape 6: Acc√©der √† l'interface

Ouvrez votre navigateur et allez sur: **http://localhost:7860**

---

## ü™ü Installation sur Windows 11

### Pr√©requis
- Windows 11 (ou Windows 10)
- Pour GPU NVIDIA: Pilotes NVIDIA r√©cents + CUDA Toolkit
- Pour CPU uniquement: aucune configuration GPU n√©cessaire

### √âtape 1: Installer Python 3.10+

1. T√©l√©chargez Python depuis [python.org](https://www.python.org/downloads/)
2. Lors de l'installation, **cochez "Add Python to PATH"**
3. V√©rifiez l'installation:

```cmd
python --version
```

### √âtape 2: Cr√©er un environnement virtuel

```cmd
# Cr√©er un dossier pour le projet
mkdir C:\smollm-app
cd C:\smollm-app

# Cr√©er un environnement virtuel
python -m venv venv

# Activer l'environnement
venv\Scripts\activate
```

### √âtape 3: Installer les d√©pendances

#### Option A: Avec GPU NVIDIA (recommand√© si disponible)

```cmd
# Mettre √† jour pip
python -m pip install --upgrade pip

# Installer PyTorch avec support CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Installer les autres d√©pendances
pip install transformers>=4.53.0 gradio>=4.0.0 accelerate pillow sentencepiece protobuf

# Optionnel: pour quantification et optimisation
pip install bitsandbytes-windows
```

#### Option B: CPU uniquement (si pas de GPU)

```cmd
# Mettre √† jour pip
python -m pip install --upgrade pip

# Installer PyTorch version CPU
pip install torch torchvision torchaudio

# Installer les autres d√©pendances
pip install transformers>=4.53.0 gradio>=4.0.0 accelerate pillow sentencepiece protobuf
```

### √âtape 4: T√©l√©charger et lancer l'application

```cmd
# Cr√©er le fichier Python
notepad app.py
# Coller le code de l'artefact et sauvegarder

# Ou utiliser PowerShell pour t√©l√©charger
# Invoke-WebRequest -Uri "https://votre-url/app.py" -OutFile "app.py"

# Lancer l'application
python app.py
```

### √âtape 5: Acc√©der √† l'interface

Ouvrez votre navigateur et allez sur: **http://localhost:7860**

---

## ‚öôÔ∏è Configuration avanc√©e

### R√©duire l'utilisation de la m√©moire

Si vous avez des probl√®mes de RAM/VRAM, modifiez ces lignes dans `app.py`:

```python
# Utiliser une quantification 8-bit (n√©cessite bitsandbytes)
from transformers import BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    bnb_8bit_compute_dtype=torch.float16
)

# Puis lors du chargement:
text_model = AutoModelForCausalLM.from_pretrained(
    TEXT_MODEL,
    quantization_config=quantization_config,
    device_map="auto"
)
```

### Acc√©der depuis d'autres appareils sur le r√©seau

Modifiez la derni√®re ligne de `app.py`:

```python
demo.launch(
    server_name="0.0.0.0",  # √âcouter sur toutes les interfaces
    server_port=7860,
    share=True  # Cr√©er un lien public temporaire (via Gradio)
)
```

### Variables d'environnement utiles

```bash
# Pour Mac/Linux
export PYTORCH_ENABLE_MPS_FALLBACK=1  # Fallback CPU si MPS √©choue
export TRANSFORMERS_CACHE=~/smollm-cache  # Cache des mod√®les

# Pour Windows (cmd)
set TRANSFORMERS_CACHE=C:\smollm-cache

# Pour Windows (PowerShell)
$env:TRANSFORMERS_CACHE="C:\smollm-cache"
```

---

## üöÄ Utilisation

### Mode Texte
1. Allez dans l'onglet "üí¨ Mode Texte"
2. Tapez votre question ou prompt
3. Ajustez les param√®tres (longueur, temp√©rature)
4. Cliquez sur "üöÄ G√©n√©rer"

### Mode Vision
1. Allez dans l'onglet "üëÅÔ∏è Mode Vision"
2. T√©l√©chargez une image
3. Posez une question sur l'image
4. Cliquez sur "üîç Analyser"

---

## ‚ùì D√©pannage

### Probl√®me: "No module named 'transformers'"
**Solution:** Assurez-vous que l'environnement virtuel est activ√© et r√©installez:
```bash
pip install transformers>=4.53.0
```

### Probl√®me: "CUDA out of memory"
**Solution:** 
- R√©duire la longueur maximale de g√©n√©ration
- Utiliser la quantification 8-bit
- Fermer les autres applications gourmandes en m√©moire

### Probl√®me: Vitesse lente sur Mac M1/M2/M3
**Solution:**
```bash
# V√©rifier que MPS est utilis√©
python -c "import torch; print(f'MPS disponible: {torch.backends.mps.is_available()}')"

# Si False, r√©installer PyTorch:
pip install --upgrade torch torchvision torchaudio
```

### Probl√®me: ModuleNotFoundError pour 'sentencepiece'
**Solution:**
```bash
pip install sentencepiece protobuf
```

### Probl√®me: L'interface ne se charge pas
**Solution:**
1. V√©rifiez les logs dans le terminal
2. Essayez un autre port:
```python
demo.launch(server_port=8080)
```
3. D√©sactivez le pare-feu temporairement

---

## üìä Configuration syst√®me recommand√©e

### Minimum (CPU uniquement)
- **RAM:** 16 GB
- **Stockage:** 20 GB libres
- **Temps de g√©n√©ration:** ~30-60 secondes

### Recommand√© (avec GPU)
- **RAM:** 16 GB
- **VRAM:** 8 GB (NVIDIA RTX 3060 ou sup√©rieur)
- **Stockage:** 20 GB libres
- **Temps de g√©n√©ration:** ~2-5 secondes

### Optimal (Apple Silicon)
- **Mod√®le:** M1 Pro/Max, M2, M3 ou sup√©rieur
- **RAM unifi√©e:** 16 GB minimum (32 GB recommand√©)
- **Stockage:** 20 GB libres
- **Temps de g√©n√©ration:** ~3-8 secondes

---

## üìö Ressources additionnelles

- **Documentation SmolLM3:** https://huggingface.co/HuggingFaceTB/SmolLM3-3B-Instruct
- **Documentation SmolVLM2:** https://huggingface.co/HuggingFaceTB/SmolVLM2-2.2B-Instruct
- **Gradio Docs:** https://www.gradio.app/docs
- **Transformers Docs:** https://huggingface.co/docs/transformers

---

## üîÑ Mise √† jour

Pour mettre √† jour l'application:

```bash
# Activer l'environnement
source venv/bin/activate  # Mac/Linux
# ou
venv\Scripts\activate  # Windows

# Mettre √† jour les packages
pip install --upgrade transformers gradio torch

# Relancer l'application
python app.py
```

---

## üéâ Bon usage !

L'interface devrait maintenant √™tre op√©rationnelle. Les mod√®les seront t√©l√©charg√©s automatiquement au premier lancement (environ 10-15 GB au total).

**Temps de t√©l√©chargement estim√©:**
- Connexion rapide (100 Mbps): ~15-20 minutes
- Connexion moyenne (50 Mbps): ~30-40 minutes
- Connexion lente (10 Mbps): 2-3 heures